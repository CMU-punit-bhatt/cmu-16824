{"cells":[{"cell_type":"markdown","metadata":{"id":"DCNX4eU6fH0e"},"source":["# Q3: Even deeper! Resnet18 for PASCAL classification (15 pts)\n","\n","Hopefully we all got much better accuracy with the deeper model! Since 2012, much deeper architectures have been proposed. [ResNet](https://arxiv.org/abs/1512.03385) is one of the popular ones. In this task, we attempt to further improve the performance with the “very deep” ResNet-18 architecture.\n","\n","\n","## 3.1 Build ResNet-18 (1 pts)\n","Write a network modules for the Resnet-18 architecture (refer to the original paper). You can use `torchvision.models` for this section, so it should be very easy! \n","Do not load the pretrained weights for this question. We will get to that in the next question."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkGKII7vdnLY","executionInfo":{"status":"ok","timestamp":1646094758267,"user_tz":300,"elapsed":13341,"user":{"displayName":"Punit Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrxmjUFMKUQAzHle30ZYoVyjo08hYnXCz-PrtI=s64","userId":"00383454386425572934"}},"outputId":"e5f7336c-0162-4c5f-9398-542deb8bfcaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n","!tar -xf VOCtrainval_06-Nov-2007.tar\n","\n","!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar \n","!tar -xf VOCtest_06-Nov-2007.tar"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fORCC4gjdnSn","executionInfo":{"status":"ok","timestamp":1646094805370,"user_tz":300,"elapsed":47107,"user":{"displayName":"Punit Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrxmjUFMKUQAzHle30ZYoVyjo08hYnXCz-PrtI=s64","userId":"00383454386425572934"}},"outputId":"fac6fcbe-49ba-4ff4-f664-f9a42a123ea9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-01 00:32:38--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n","Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n","Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 460032000 (439M) [application/x-tar]\n","Saving to: ‘VOCtrainval_06-Nov-2007.tar’\n","\n","VOCtrainval_06-Nov- 100%[===================>] 438.72M  19.3MB/s    in 22s     \n","\n","2022-03-01 00:33:00 (19.6 MB/s) - ‘VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n","\n","--2022-03-01 00:33:02--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n","Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n","Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 451020800 (430M) [application/x-tar]\n","Saving to: ‘VOCtest_06-Nov-2007.tar’\n","\n","VOCtest_06-Nov-2007 100%[===================>] 430.13M  21.8MB/s    in 21s     \n","\n","2022-03-01 00:33:23 (20.7 MB/s) - ‘VOCtest_06-Nov-2007.tar’ saved [451020800/451020800]\n","\n"]}]},{"cell_type":"code","source":["%cd drive/MyDrive/spring22/16824/hw1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbiYFlwOdoKN","executionInfo":{"status":"ok","timestamp":1646094805710,"user_tz":300,"elapsed":348,"user":{"displayName":"Punit Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrxmjUFMKUQAzHle30ZYoVyjo08hYnXCz-PrtI=s64","userId":"00383454386425572934"}},"outputId":"93a9edc6-4331-4fc1-f3aa-148738a41739"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/spring22/16824/hw1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HTGAe_--fH0j"},"outputs":[],"source":["from collections import OrderedDict\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import models\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import trainer\n","from utils import ARGS\n","from simple_cnn import SimpleCNN\n","from voc_dataset import VOCDataset\n","\n","model = models.resnet18()\n","n_inputs = model.fc.in_features\n","classifier = nn.Sequential(OrderedDict([\n","    ('fc1', nn.Linear(n_inputs, 20))\n","]))\n","model.fc = classifier"]},{"cell_type":"markdown","metadata":{"id":"IoLagN5efH0k"},"source":["## 3.2 Add Tensorboard Summaries (6 pts)\n","You should've already written tensorboard summary generation code into `trainer.py` from q1. However, you probably just added the most basic summary features. Please implement the more advanced summaries listed here:\n","* training loss (should be done)\n","* testing MAP curves (should be done)\n","* learning rate\n","* [histogram of gradients](https://www.tensorflow.org/api_docs/python/tf/summary/histogram)\n","\n","## 3.3 Train and Test (8 pts)\n","Use the same hyperparameter settings from Task 2, and train the model for 50 epochs. Tune hyperparameters properly to get mAP around 0.5. Report tensorboard screenshots for *all* of the summaries listed above (for image summaries show screenshots at $n \\geq 3$ iterations). For the histograms, include the screenshots of the gradients of layer1.1.conv1.weight and layer4.0.bn2.bias.\n","\n","**REMEMBER TO SAVE A MODEL AT THE END OF TRAINING**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olvWzOy0fH0l","outputId":"b6f188c1-cc60-4af9-b3c1-e06e7d0d4185","executionInfo":{"status":"ok","timestamp":1646098484097,"user_tz":300,"elapsed":3669675,"user":{"displayName":"Punit Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrxmjUFMKUQAzHle30ZYoVyjo08hYnXCz-PrtI=s64","userId":"00383454386425572934"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 0 [0 (0%)]\tLoss: 0.680367\n","Test MAP: 0.07267379250981906\n","Train Epoch: 0 [100 (64%)]\tLoss: 0.228092\n","Train Epoch: 1 [200 (27%)]\tLoss: 0.228333\n","Test MAP: 0.15880824333732985\n","Train Epoch: 1 [300 (91%)]\tLoss: 0.218712\n","Train Epoch: 2 [400 (55%)]\tLoss: 0.255169\n","Train Epoch: 3 [500 (18%)]\tLoss: 0.221265\n","Test MAP: 0.1852035916981362\n","Train Epoch: 3 [600 (82%)]\tLoss: 0.256896\n","Train Epoch: 4 [700 (46%)]\tLoss: 0.191770\n","Test MAP: 0.22270256552115889\n","Train Epoch: 5 [800 (10%)]\tLoss: 0.213907\n","Train Epoch: 5 [900 (73%)]\tLoss: 0.217533\n","Train Epoch: 6 [1000 (37%)]\tLoss: 0.218733\n","Test MAP: 0.16963835101949773\n","Train Epoch: 7 [1100 (1%)]\tLoss: 0.205616\n","Train Epoch: 7 [1200 (64%)]\tLoss: 0.211461\n","Test MAP: 0.27255797500866547\n","Train Epoch: 8 [1300 (28%)]\tLoss: 0.203046\n","Train Epoch: 8 [1400 (92%)]\tLoss: 0.228429\n","Train Epoch: 9 [1500 (55%)]\tLoss: 0.193764\n","Test MAP: 0.2841128683142301\n","Train Epoch: 10 [1600 (19%)]\tLoss: 0.203189\n","Train Epoch: 10 [1700 (83%)]\tLoss: 0.194310\n","Test MAP: 0.3164940296288759\n","Train Epoch: 11 [1800 (46%)]\tLoss: 0.210079\n","Train Epoch: 12 [1900 (10%)]\tLoss: 0.192975\n","Train Epoch: 12 [2000 (74%)]\tLoss: 0.192597\n","Test MAP: 0.3352182274412029\n","Train Epoch: 13 [2100 (38%)]\tLoss: 0.194570\n","Train Epoch: 14 [2200 (1%)]\tLoss: 0.197320\n","Test MAP: 0.3488148183247727\n","Train Epoch: 14 [2300 (65%)]\tLoss: 0.203548\n","Train Epoch: 15 [2400 (29%)]\tLoss: 0.172414\n","Train Epoch: 15 [2500 (92%)]\tLoss: 0.173731\n","Test MAP: 0.3855402911516952\n","Train Epoch: 16 [2600 (56%)]\tLoss: 0.183816\n","Train Epoch: 17 [2700 (20%)]\tLoss: 0.171038\n","Test MAP: 0.3884842873834674\n","Train Epoch: 17 [2800 (83%)]\tLoss: 0.197171\n","Train Epoch: 18 [2900 (47%)]\tLoss: 0.203868\n","Train Epoch: 19 [3000 (11%)]\tLoss: 0.161355\n","Test MAP: 0.3788091983907984\n","Train Epoch: 19 [3100 (75%)]\tLoss: 0.206528\n","Train Epoch: 20 [3200 (38%)]\tLoss: 0.168407\n","Test MAP: 0.4097037671874271\n","Train Epoch: 21 [3300 (2%)]\tLoss: 0.173214\n","Train Epoch: 21 [3400 (66%)]\tLoss: 0.173078\n","Train Epoch: 22 [3500 (29%)]\tLoss: 0.158615\n","Test MAP: 0.4419700213502872\n","Train Epoch: 22 [3600 (93%)]\tLoss: 0.175087\n","Train Epoch: 23 [3700 (57%)]\tLoss: 0.187803\n","Test MAP: 0.39289538928490125\n","Train Epoch: 24 [3800 (20%)]\tLoss: 0.171892\n","Train Epoch: 24 [3900 (84%)]\tLoss: 0.176973\n","Train Epoch: 25 [4000 (48%)]\tLoss: 0.166921\n","Test MAP: 0.44896090940901273\n","Train Epoch: 26 [4100 (11%)]\tLoss: 0.173613\n","Train Epoch: 26 [4200 (75%)]\tLoss: 0.195123\n","Test MAP: 0.4474066807907965\n","Train Epoch: 27 [4300 (39%)]\tLoss: 0.199001\n","Train Epoch: 28 [4400 (3%)]\tLoss: 0.159402\n","Train Epoch: 28 [4500 (66%)]\tLoss: 0.184872\n","Test MAP: 0.4382590553922355\n","Train Epoch: 29 [4600 (30%)]\tLoss: 0.162561\n","Train Epoch: 29 [4700 (94%)]\tLoss: 0.188232\n","Test MAP: 0.4923739306194516\n","Train Epoch: 30 [4800 (57%)]\tLoss: 0.183042\n","Train Epoch: 31 [4900 (21%)]\tLoss: 0.166881\n","Train Epoch: 31 [5000 (85%)]\tLoss: 0.130805\n","Test MAP: 0.4762584275617307\n","Train Epoch: 32 [5100 (48%)]\tLoss: 0.181744\n","Train Epoch: 33 [5200 (12%)]\tLoss: 0.147336\n","Test MAP: 0.5025387857418251\n","Train Epoch: 33 [5300 (76%)]\tLoss: 0.193357\n","Train Epoch: 34 [5400 (39%)]\tLoss: 0.121932\n","Train Epoch: 35 [5500 (3%)]\tLoss: 0.186098\n","Test MAP: 0.5086417656576472\n","Train Epoch: 35 [5600 (67%)]\tLoss: 0.132310\n","Train Epoch: 36 [5700 (31%)]\tLoss: 0.159057\n","Test MAP: 0.507658896948626\n","Train Epoch: 36 [5800 (94%)]\tLoss: 0.178966\n","Train Epoch: 37 [5900 (58%)]\tLoss: 0.165706\n","Train Epoch: 38 [6000 (22%)]\tLoss: 0.148639\n","Test MAP: 0.5003754910811378\n","Train Epoch: 38 [6100 (85%)]\tLoss: 0.169036\n","Train Epoch: 39 [6200 (49%)]\tLoss: 0.169342\n","Test MAP: 0.5257722368836992\n","Train Epoch: 40 [6300 (13%)]\tLoss: 0.144965\n","Train Epoch: 40 [6400 (76%)]\tLoss: 0.169611\n","Train Epoch: 41 [6500 (40%)]\tLoss: 0.134173\n","Test MAP: 0.5257266571466899\n","Train Epoch: 42 [6600 (4%)]\tLoss: 0.145890\n","Train Epoch: 42 [6700 (68%)]\tLoss: 0.172049\n","Test MAP: 0.5199774700099173\n","Train Epoch: 43 [6800 (31%)]\tLoss: 0.121985\n","Train Epoch: 43 [6900 (95%)]\tLoss: 0.138940\n","Train Epoch: 44 [7000 (59%)]\tLoss: 0.144042\n","Test MAP: 0.5248561739755913\n","Train Epoch: 45 [7100 (22%)]\tLoss: 0.181207\n","Train Epoch: 45 [7200 (86%)]\tLoss: 0.110678\n","Test MAP: 0.5366471929471976\n","Train Epoch: 46 [7300 (50%)]\tLoss: 0.156203\n","Train Epoch: 47 [7400 (13%)]\tLoss: 0.139104\n","Train Epoch: 47 [7500 (77%)]\tLoss: 0.149663\n","Test MAP: 0.5490545232463744\n","Train Epoch: 48 [7600 (41%)]\tLoss: 0.151324\n","Train Epoch: 49 [7700 (4%)]\tLoss: 0.129846\n","Test MAP: 0.5411160334710166\n","Train Epoch: 49 [7800 (68%)]\tLoss: 0.144175\n","Train Epoch: 50 [7900 (32%)]\tLoss: 0.160824\n","Train Epoch: 50 [8000 (96%)]\tLoss: 0.149650\n","Test MAP: 0.5380532079145182\n","Train Epoch: 51 [8100 (59%)]\tLoss: 0.151705\n","Train Epoch: 52 [8200 (23%)]\tLoss: 0.120128\n","Test MAP: 0.5434378204668497\n","Train Epoch: 52 [8300 (87%)]\tLoss: 0.162717\n","Train Epoch: 53 [8400 (50%)]\tLoss: 0.142133\n","Train Epoch: 54 [8500 (14%)]\tLoss: 0.136045\n","Test MAP: 0.5655563496040245\n","Train Epoch: 54 [8600 (78%)]\tLoss: 0.135872\n","Train Epoch: 55 [8700 (41%)]\tLoss: 0.143578\n","Test MAP: 0.5646663372940928\n","Train Epoch: 56 [8800 (5%)]\tLoss: 0.147704\n","Train Epoch: 56 [8900 (69%)]\tLoss: 0.116326\n","Train Epoch: 57 [9000 (32%)]\tLoss: 0.133726\n","Test MAP: 0.5643641542255724\n","Train Epoch: 57 [9100 (96%)]\tLoss: 0.130383\n","Train Epoch: 58 [9200 (60%)]\tLoss: 0.107850\n","Test MAP: 0.5599693192034015\n","Train Epoch: 59 [9300 (24%)]\tLoss: 0.105499\n","Train Epoch: 59 [9400 (87%)]\tLoss: 0.153605\n","Train Epoch: 60 [9500 (51%)]\tLoss: 0.096762\n","Test MAP: 0.57161228044489\n","Train Epoch: 61 [9600 (15%)]\tLoss: 0.137419\n","Train Epoch: 61 [9700 (78%)]\tLoss: 0.124292\n","Test MAP: 0.5911942489135873\n","Train Epoch: 62 [9800 (42%)]\tLoss: 0.145489\n","Train Epoch: 63 [9900 (6%)]\tLoss: 0.153496\n","Train Epoch: 63 [10000 (69%)]\tLoss: 0.110649\n","Test MAP: 0.5780273360668737\n","Train Epoch: 64 [10100 (33%)]\tLoss: 0.122031\n","Train Epoch: 64 [10200 (97%)]\tLoss: 0.116800\n","Test MAP: 0.5871590105868535\n","Train Epoch: 65 [10300 (61%)]\tLoss: 0.121581\n","Train Epoch: 66 [10400 (24%)]\tLoss: 0.105683\n","Train Epoch: 66 [10500 (88%)]\tLoss: 0.121217\n","Test MAP: 0.5623338134540805\n","Train Epoch: 67 [10600 (52%)]\tLoss: 0.130983\n","Train Epoch: 68 [10700 (15%)]\tLoss: 0.131800\n","Test MAP: 0.5580826444753424\n","Train Epoch: 68 [10800 (79%)]\tLoss: 0.117246\n","Train Epoch: 69 [10900 (43%)]\tLoss: 0.133447\n","test map: 0.5873304797830045\n"]}],"source":["args = ARGS(epochs=70,\n","            batch_size=32,\n","            lr=0.0005,\n","            use_cuda=True,\n","            step_size=30,\n","            save_freq=20,\n","            save_at_end=True,\n","            val_every=250)\n","model_name = 'ResNet9'\n","optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n","test_ap, test_map = trainer.train(args, model, optimizer, scheduler, model_name=model_name)\n","print('test map:', test_map)"]},{"cell_type":"code","source":["%load_ext tensorboard\n","\n","%tensorboard --logdir runs/ResNet3/"],"metadata":{"id":"YiZ9f2Z7ypNR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"G0Cigl0LhPl3"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"colab":{"name":"q3_resnet.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}